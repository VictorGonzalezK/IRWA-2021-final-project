{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√≠ctor Gonz√°lez Kullmann u161806<br>\n",
    "Albert Baito Pan√© u161812\n",
    "\n",
    "## PART 2: Indexing and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import json\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "#2\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import math\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to load the desired file containing the tweets\n",
    "def load_data(file_name):\n",
    "    with open(file_name) as f:\n",
    "        tweets=json.load(f)\n",
    "    return tweets\n",
    "        \n",
    "tweets = load_data(\"dataset_tweets_WHO.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that transforms the iso lenguage in the complete name\n",
    "def iso_leng_translate(leng):\n",
    "    return pycountry.languages.get(alpha_2=leng).name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tl', 'ja', 'in', 'uk', 'ps', 'es', 'ru', 'und', 'en', 'ar', 'fr', 'de'}\n"
     ]
    }
   ],
   "source": [
    "#get all the languages in the tweets of the datasets and get the stopwords of that language if available\n",
    "def create_stopword_dict(tweets):\n",
    "    #get languages\n",
    "    lang=[]\n",
    "    for i in range(len(tweets)):\n",
    "        lang.append((tweets[str(i)]['lang']))\n",
    "    languages = set(lang)\n",
    "    print(languages)\n",
    "    \n",
    "    #search for the stopwords and save them in a dictionary for later usage\n",
    "    lang_dict = {}\n",
    "    for i in languages:     \n",
    "        try:\n",
    "            #transform ISO lenguage in complete name for convenience\n",
    "            lang_dict [i] = set(stopwords.words(iso_leng_translate(i)))\n",
    "            \n",
    "        #if we don't have a stopwords available for that lenguage we just skip\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    return lang_dict\n",
    "\n",
    "stopwords_bylang = create_stopword_dict(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(tweet, stopwordsByLan):\n",
    "    \n",
    "    #get the tweet text\n",
    "    og_tweet_text = (tweet['full_text']) \n",
    "\n",
    "    #lowercase to uniform format and split to get words\n",
    "    og_tweet_text = og_tweet_text.lower()   \n",
    "    og_tweet_text = og_tweet_text.split()\n",
    "\n",
    "    #create our pattern to avoid removing #\n",
    "\n",
    "    #remove punctuation\n",
    "    tweet_text=[]\n",
    "    for word in og_tweet_text:\n",
    "        #maintain the links in the correct format\n",
    "        if \"https\" not in word:\n",
    "            #delete all punctuation conserving the # and @(in tweets are meaninguful)\n",
    "            word = re.sub(r'[^\\w\\s#@]','', word)\n",
    "            word = re.sub(r'_','',word)\n",
    "\n",
    "        if word:\n",
    "            tweet_text.append(word) \n",
    "\n",
    "\n",
    "    #get lenguage to filter stpowords\n",
    "    tweet_lang = tweet['lang'].lower()\n",
    "    #check availability of stopwors dict\n",
    "    if tweet_lang in stopwordsByLan.keys():\n",
    "        #if possible filter stopwords\n",
    "        stop_words = set(stopwordsByLan[tweet_lang])\n",
    "        clean_text = []\n",
    "        for word in tweet_text:\n",
    "            if word not in stop_words:\n",
    "                clean_text.append(word)\n",
    "\n",
    "    #if stopwords are not available in some lenguage just let them \n",
    "    else:\n",
    "        clean_text = tweet_text    \n",
    "\n",
    "\n",
    "    #stem the words with the correct format for each lenguage\n",
    "    try:\n",
    "        stemmer = SnowballStemmer(iso_leng_translate(tweet_lang))\n",
    "        clean_text = [stemmer.stem(word) for word in clean_text]\n",
    "\n",
    "    except:\n",
    "        pass   \n",
    "        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function created to search for tweet id of a concrete lenguage\n",
    "def tweet_lenguageSearcher(tweets, leng):\n",
    "    for i in range(len(tweets)):\n",
    "        if (tweets[str(i)]['lang']) == leng:\n",
    "            print(tweets[str(i)]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448163383493136385\n",
      "1447422682711068673\n",
      "1447421758437564417\n",
      "1447421622235942912\n",
      "1446492798493003779\n",
      "1437873802952708097\n",
      "1437873628792639490\n",
      "1436055322376949761\n",
      "1436055263312818176\n",
      "1426242406853353474\n",
      "1425836042599374848\n",
      "1425212438354571265\n",
      "1424986407857238034\n",
      "1423905220250243074\n",
      "1423662605516804097\n",
      "1422204917876461572\n",
      "1421895908669763586\n",
      "1411320867456434177\n",
      "1409244087962775557\n"
     ]
    }
   ],
   "source": [
    "tweet_lenguageSearcher(tweets, \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot the og tweet to check for the data processing correctness\n",
    "def tweet_Printer(tweets, id):\n",
    "    for i in range(len(tweets)):\n",
    "            if (tweets[str(i)]['id']) == id:\n",
    "                print(tweets[str(i)]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Ops_Paraguay: üë•La salud comunitaria est√° en el centro de la vacunaci√≥n contra la COVID-19 en comunidades ind√≠genas de Paraguay\n",
      "‚ûïINFOüëâ:‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "tweet_Printer(tweets, 1426242406853353474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inverted index\n",
    "def create_index(tweets, stopwordsByLan):\n",
    "    \"\"\"\n",
    "    Impleent the inverted index\n",
    "    \n",
    "    Argument:\n",
    "    collection of tweets\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index containing terms as keys and the corresponding \n",
    "    list of tweets these keys appears in (and the positions) as values.\n",
    "    tf - normalized term frequency for each term in each tweet\n",
    "    idf - inverse document frequency of each term\n",
    "    \"\"\"\n",
    "    \n",
    "    index = defaultdict(list) \n",
    "    \n",
    "    tf = defaultdict(list)        #term frequencies of terms in tweets \n",
    "    df = defaultdict(int)         #tweet frequencies of terms in the collection\n",
    "    idf = defaultdict(float)\n",
    "    \n",
    "    N = len(tweets)\n",
    "    \n",
    "    for tweet_num, tweet in tweets.items(): \n",
    "        #get the id of the tweet\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        #get the terms cleaned \n",
    "        terms = clean_data(tweet, stopwordsByLan)\n",
    "                \n",
    "        termdictTweet = {}\n",
    "\n",
    "        for position, term in enumerate(terms): # terms in the tweet\n",
    "            try:\n",
    "                # if the term is already in the index for the current tweet\n",
    "                # append the position to the corrisponding list\n",
    "                \n",
    "                termdictTweet[term][tweet_id].append(position)  \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                termdictTweet[term]=[tweet_id, array('I',[position])] #'I' indicates unsigned int (int in python)\n",
    "        \n",
    "        \n",
    "        #normalize term frequencies\n",
    "        # Compute the denominator to normalize term frequencies\n",
    "        # norm is the same for all terms of a tweet.\n",
    "        norm = 0\n",
    "        for term, posting in termdictTweet.items(): \n",
    "            # posting is a list containing tweet_id and the list of positions for current term in current tweet: \n",
    "            # posting ==> [tweet_id, [list of positions]] \n",
    "            # you can use it to inferr the frequency of current term.\n",
    "            norm+=len(posting[1])**2\n",
    "        \n",
    "        norm = math.sqrt(norm)\n",
    "\n",
    "\n",
    "        #calculate the tf (dividing the term frequency by the above computed norm) and df weights\n",
    "        for term, posting in termdictTweet.items():     \n",
    "            # append the tf for current term (tf = term frequency in current tweet/norm)\n",
    "            tf[term].append(np.round(len(posting[1])/norm ,4))  \n",
    "            #increment the document frequency of current term (number of tweets containing the current term)\n",
    "            df[term] += 1  # increment df for current term\n",
    "        \n",
    "        # Compute idf \n",
    "        for term in df:\n",
    "            idf[term] = np.round(np.log(float(N/df[term])),4)\n",
    "        \n",
    "        #merge the current tweet index with the main index\n",
    "        for termpage, postingpage in termdictTweet.items():\n",
    "            index[termpage].append(postingpage)\n",
    "                      \n",
    "                    \n",
    "    return index, tf, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 97.95 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "inverted_index, tf, idf= create_index(tweets, stopwords_bylang)\n",
    "print(\"Total time to create the index: {} seconds\" .format(np.round(time.time() - start_time,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankTweets(terms, tweets_ids, index, idf, tf):\n",
    "    \"\"\"\n",
    "    Perform the ranking of the results of a search based on the tf-idf weights\n",
    "    \n",
    "    Argument:\n",
    "    terms -- list of query terms\n",
    "    tweets_ids -- list of tweet ids, to rank, matching the query\n",
    "    index -- inverted index data structure\n",
    "    idf -- inverted document frequencies\n",
    "    tf -- term frequencies\n",
    "    titleIndex -- mapping between page id and page title\n",
    "    \n",
    "    Returns:\n",
    "    resultScores --  List of ranked scores of tweets\n",
    "    resultTweets --  List of ranked tweet ids\n",
    "    \"\"\"\n",
    "        \n",
    "    # I'm interested only on the element of the tweetVector corresponding to the query terms \n",
    "    # The remaing elements would became 0 when multiplied to the queryVector\n",
    "    tweetVectors = defaultdict(lambda: [0]*len(terms))\n",
    "    queryVector = [0]*len(terms)    \n",
    "\n",
    "    # compute the norm for the query tf\n",
    "    query_terms_count = collections.Counter(terms) # get the frequency of each term in the query. \n",
    "        \n",
    "    query_norm = la.norm(list(query_terms_count.values()))\n",
    "    \n",
    "    for termIndex, term in enumerate(terms): #termIndex is the index of the term in the query\n",
    "        if term not in index:\n",
    "            continue\n",
    "                    \n",
    "        ##¬†Compute tf*idf(normalize tf as done with tweets)\n",
    "        queryVector[termIndex]= query_terms_count[term]/query_norm * idf[term] \n",
    "\n",
    "        # Generate tweetVectors for matching tweets\n",
    "        for tweetIndex, (tweet_id, postings) in enumerate(index[term]):\n",
    "            \n",
    "            \n",
    "            if tweet_id in tweets_ids:\n",
    "                tweetVectors[tweet_id][termIndex] = tf[term][tweetIndex] * idf[term]\n",
    "\n",
    "    # calculate the score of each tweet\n",
    "    # compute the cosine similarity between queyVector and each tweetVector:\n",
    "        \n",
    "    tweetScores = [ [np.dot(curTweetVec, queryVector), tweet_id] for tweet_id, curTweetVec in tweetVectors.items() ]\n",
    "    tweetScores.sort(reverse=True)\n",
    "    resultTweets = [x[1] for x in tweetScores]\n",
    "    resultScores = [x[0] for x in tweetScores]\n",
    "    \n",
    "    if len(resultTweets) == 0:\n",
    "        print(\"No results found, try again\")\n",
    "        \n",
    "    #return rank punctuation and ids\n",
    "    return resultScores, resultTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(tweet):\n",
    "    hashtags = list()\n",
    "    for hashtag in tweet[\"entities\"][\"hashtags\"]:\n",
    "        hashtags.append(\"#\"+hashtag[\"text\"])\n",
    "    return ' '.join(hashtags).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_Searcher(tweets, id):\n",
    "    for tweet in tweets.values():\n",
    "            if (tweet['id']) == id:\n",
    "                return \"Tweet: \" + str(tweet['full_text']) + \"|\" + \"Username: \" + str(tweet[\"user\"][\"name\"]) + \"|\" + \"Date: \"+ str(tweet[\"created_at\"]) + \"|\" + \"Hashtags: \" + get_hashtags(tweet) + \"|\" + \"Likes: \" +  str(tweet[\"favorite_count\"]) + \"|\" + \"Retweets: \"+ str(tweet[\"retweet_count\"]) + \"|\" + \"Url: \" + \"twitter.com/\"+str(tweet[\"user\"][\"id\"])+\"/status/\"+tweet['id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_search(query, index, stopwordsByLan, tweets, tf, idf, scores):\n",
    "    '''\n",
    "    As we are working with conjunctive queries. \n",
    "    The output is either the needed data of tweets that contain all of the query terms, if scores is False, or \n",
    "    the tweet ids and the scores of tweets that contain all query terms if scores is True.\n",
    "    '''\n",
    "    query = clean_data(query, stopwordsByLan)\n",
    "    tweet_ids = []\n",
    "    for pos, term in enumerate(query):\n",
    "        try: \n",
    "            #store the ids of Tweets that contain \"term\"                        \n",
    "            termTweets = [posting[0] for posting in index[term]]\n",
    "            #the first term tweet ids are aved to compute intersection with later terms\n",
    "            if pos == 0:\n",
    "                tweet_ids = set(termTweets)\n",
    "                \n",
    "            else:  \n",
    "                tweet_ids = tweet_ids.intersection(termTweets)\n",
    "        except:\n",
    "            #term is not in index stop searching\n",
    "            print(\"This query has no result in the collection\")\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    #rank by tf-idf\n",
    "    rank_scores, ranked_tweets = rankTweets(query, tweet_ids, index, idf, tf)  \n",
    "    \n",
    "    #search for the information of the selected tweets\n",
    "    return_list=[]\n",
    "    for tweet_id in ranked_tweets:\n",
    "        return_list.append(tweet_Searcher(tweets, tweet_id))\n",
    "    \n",
    "    if scores:\n",
    "        return rank_scores, ranked_tweets\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  covid19 pandemic\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 8 for the seached query:\n",
      "\n",
      "Tweet: RT @UNICEF: Your guide to breastfeeding safely during the COVID-19 pandemic. \n",
      "\n",
      "#WorldBreastfeedingWeek https://t.co/8EaLDselmn|Username: World Health Organization (WHO)|Date: Sun Aug 01 16:29:25 +0000 2021|Hashtags: #WorldBreastfeedingWeek|Likes: 0|Retweets: 278|Url: twitter.com/14499829/status/1421870697094205445\n",
      "\n",
      "\n",
      "Tweet: üíâüíâüíâüíâ\n",
      "üíâüíâüíâüíâ\n",
      "üíâüíâüíâüíâ\n",
      "üíâüíâüíâüíâ\n",
      "üíâüíâüíâüíâ                 üíâüíâüíâüíâ\n",
      "üíâüíâüíâüíâ                 üíâüíâüíâüíâ\n",
      "\n",
      "COVID-19 vaccines     COVID-19 vaccines\n",
      "in 10 countries             in the rest of the üåç\n",
      "\n",
      "#VaccinEquity is üóùÔ∏è to ending the pandemic, together!\n",
      "\n",
      "#WorldEmojiDay|Username: World Health Organization (WHO)|Date: Sat Jul 17 16:24:23 +0000 2021|Hashtags: #VaccinEquity #WorldEmojiDay|Likes: 3486|Retweets: 1517|Url: twitter.com/14499829/status/1416433609091653633\n",
      "\n",
      "\n",
      "Tweet: RT @WHOAFRO: üì∫ LIVE: @WHOAFRO press briefing on the #COVID19 pandemic, genome sequencing and COVID-19 variants in #Africa. Dr @MoetiTshidi‚Ä¶|Username: World Health Organization (WHO)|Date: Thu Sep 09 10:03:33 +0000 2021|Hashtags: #COVID19 #Africa|Likes: 0|Retweets: 45|Url: twitter.com/14499829/status/1435906715497766918\n",
      "\n",
      "\n",
      "Tweet: RT @WHOAFRO: üì∫ LIVE: @WHOAFRO media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶|Username: World Health Organization (WHO)|Date: Thu Sep 30 10:07:43 +0000 2021|Hashtags: #COVID19|Likes: 0|Retweets: 27|Url: twitter.com/14499829/status/1443517908072730624\n",
      "\n",
      "\n",
      "Tweet: RT @WHOAFRO: Join tomorrow's @WHOAFRO LIVE press briefing on the #COVID19 pandemic, genome sequencing and COVID-19 variants in #Africa. Dr‚Ä¶|Username: World Health Organization (WHO)|Date: Wed Sep 08 13:38:53 +0000 2021|Hashtags: #COVID19 #Africa|Likes: 0|Retweets: 51|Url: twitter.com/14499829/status/1435598519595843585\n",
      "\n",
      "\n",
      "Tweet: RT @WHOAFRO: Join tomorrow's media briefing on the #COVID19 pandemic &amp; the global 10% COVID-19 vaccination milestones reached by countries‚Ä¶|Username: World Health Organization (WHO)|Date: Wed Sep 29 19:01:27 +0000 2021|Hashtags: #COVID19|Likes: 0|Retweets: 21|Url: twitter.com/14499829/status/1443289841698025473\n",
      "\n",
      "\n",
      "Tweet: üìô The new book aims to help children stay positive during the #COVID19 pandemic.\n",
      "The story is a sequel to the very well-received ‚ÄòMy Hero is You: how kids can fight COVID-19!‚Äô, released in April 2020. https://t.co/JiURHza3ff https://t.co/GigV0LGWWH https://t.co/yiPs9W1CBn|Username: World Health Organization (WHO)|Date: Sat Sep 25 12:07:17 +0000 2021|Hashtags: #COVID19|Likes: 223|Retweets: 74|Url: twitter.com/14499829/status/1441736058421477381\n",
      "\n",
      "\n",
      "Tweet: WHO continues to fight the #COVID19 pandemic, supporting and accelerating progress on #VaccinEquity in countries around the üåçüåéüåè.\n",
      "\n",
      "Read #WHOImpact stories to see how our donors &amp; partners help strengthen our COVID-19 response.üëâhttps://t.co/7hT3oHxDiG https://t.co/mnu6pnJB8U|Username: World Health Organization (WHO)|Date: Mon Aug 23 08:38:30 +0000 2021|Hashtags: #COVID19 #VaccinEquity #WHOImpact|Likes: 171|Retweets: 40|Url: twitter.com/14499829/status/1429724718693634052\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wirte the queries respecting the format of the cleaner\n",
    "#specify the lang of the query to stem it and remove stopwords in a correct form\n",
    "query = {\"full_text\":\"covid19 pandemic\", \"lang\":\"en\"}\n",
    "tweets_answers = query_search(query, inverted_index, stopwords_bylang, tweets, tf, idf, False)    \n",
    "top = 10\n",
    "print(\"Query: \", query[\"full_text\"])\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the seached query:\\n\".format(top, len(tweets_answers)))\n",
    "for t_id in tweets_answers[:top] :\n",
    "    print(t_id)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  vaccine africa\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 17 for the seached query:\n",
      "\n",
      "Tweet: RT @DrTedros: Over 5.7 billion #COVID19 vaccine doses have been administered globally, but only 2% were given in Africa. This hurts all of‚Ä¶|Username: World Health Organization (WHO)|Date: Wed Sep 15 10:32:25 +0000 2021|Hashtags: #COVID19|Likes: 0|Retweets: 193|Url: twitter.com/14499829/status/1438088306965762048\n",
      "\n",
      "\n",
      "Tweet: .@DrTedros and the group of global health leaders issued an urgent call to accelerate #COVID19 vaccination globally and in Africa in particular üëâ https://t.co/2hTLpRJ2xH \n",
      "\n",
      "#VaccinEquity\n",
      "\n",
      "https://t.co/U56PfHxeug|Username: World Health Organization (WHO)|Date: Tue Sep 14 19:47:01 +0000 2021|Hashtags: #COVID19 #VaccinEquity|Likes: 207|Retweets: 69|Url: twitter.com/14499829/status/1437865487879319561\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"In low-income countries, most of which are in Africa, less than 2% of adults are fully vaccinated, compared with almost 50% in high‚Äëincome countries\"-@DrTedros #VaccinEquity https://t.co/fjD0FCooh1|Username: World Health Organization (WHO)|Date: Wed Sep 01 15:07:53 +0000 2021|Hashtags: #VaccinEquity|Likes: 63|Retweets: 26|Url: twitter.com/14499829/status/1433084202426290185\n",
      "\n",
      "\n",
      "Tweet: @MedsPatentPool @MRCza @AfricaCDC Crucially, this platform for innovation in #COVID19 vaccines is sustainable, inclusive, and will lead to vaccine security for Africa in the future. https://t.co/o9ZDybhM13 #VaccinEquity|Username: World Health Organization (WHO)|Date: Fri Jul 30 15:34:15 +0000 2021|Hashtags: #COVID19 #VaccinEquity|Likes: 77|Retweets: 27|Url: twitter.com/14499829/status/1421132036941697025\n",
      "\n",
      "\n",
      "Tweet: @DrTedros @mohgovgh @MOH_Kenya @health_malawi \"I thank the researchers in Africa who generated the data and insights that informed this decision ‚Äì this is a vaccine developed in Africa, by African scientists\"-@DrTedros #EndMalaria|Username: World Health Organization (WHO)|Date: Wed Oct 06 15:58:02 +0000 2021|Hashtags: #EndMalaria|Likes: 212|Retweets: 66|Url: twitter.com/14499829/status/1445780396151476243\n",
      "\n",
      "\n",
      "Tweet: \"Between now and the end of the year, we expect the volume of vaccines coming to Africa to increase substantially. That makes it crucial that all countries step up their preparations to roll out vaccines.\"-@DrTedros at #RC71AFRO|Username: World Health Organization (WHO)|Date: Tue Aug 24 09:21:01 +0000 2021|Hashtags: #RC71AFRO|Likes: 34|Retweets: 11|Url: twitter.com/14499829/status/1430097807659184129\n",
      "\n",
      "\n",
      "Tweet: @DrTedros @ACTAccelerator \"We urge J&amp;J to urgently prioritize distribution of their vaccines to Africa before considering supplies to rich countries that already have sufficient access\"-@DrTedros #VaccinEquity \n",
      "https://t.co/JSDJ2LniYn|Username: World Health Organization (WHO)|Date: Wed Aug 18 13:53:09 +0000 2021|Hashtags: #VaccinEquity|Likes: 81|Retweets: 48|Url: twitter.com/14499829/status/1427991963932975108\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"While vaccines were being rolled out in the wealthiest countries, Harriet was one of many #healthworkers in Africa and around the üåç who was still waiting for her turn to be vaccinated. At the time, #Uganda ‚Äì like much of Africa ‚Äì had relatively few cases of #COVID19\"-@DrTedros|Username: World Health Organization (WHO)|Date: Wed Aug 04 13:11:41 +0000 2021|Hashtags: #healthworkers #Uganda #COVID19|Likes: 78|Retweets: 35|Url: twitter.com/14499829/status/1422908098348474372\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"More than 5.7B [#COVID19 vaccine] doses have been administered globally, but only 2% of those have been administered in Africa. This leaves people at high risk of disease &amp; death exposed to a deadly virus against which many other people around the üåç enjoy protection\"-@DrTedros|Username: World Health Organization (WHO)|Date: Tue Sep 14 14:12:04 +0000 2021|Hashtags: #COVID19|Likes: 92|Retweets: 45|Url: twitter.com/14499829/status/1437781194498875401\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"So far just 2 countries in Africa have reached the 40% target, the lowest of any region. That‚Äôs not because African countries don‚Äôt have the capacity or experience to roll out #COVID19 vaccines. It‚Äôs because they've been left behind by the rest of the üåç\"-@DrTedros #VaccinEquity|Username: World Health Organization (WHO)|Date: Tue Sep 14 14:11:23 +0000 2021|Hashtags: #COVID19 #VaccinEquity|Likes: 88|Retweets: 43|Url: twitter.com/14499829/status/1437781025908736012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wirte the queries respecting the format of the cleaner\n",
    "#specify the lang of the query to stem it and remove stopwords in a correct form\n",
    "query = {\"full_text\":\"vaccine africa\", \"lang\":\"en\"}\n",
    "tweets_answers = query_search(query, inverted_index, stopwords_bylang, tweets, tf, idf, False)    \n",
    "top = 10\n",
    "print(\"Query: \", query[\"full_text\"])\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the seached query:\\n\".format(top, len(tweets_answers)))\n",
    "for t_id in tweets_answers[:top] :\n",
    "    print(t_id)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  climate crisis\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 6 for the seached query:\n",
      "\n",
      "Tweet: @DrTedros \"The humanitarian system is being pushed to its absolute limit - and beyond - by the climate crisis, natural disasters, conflict and the #COVID19 pandemic\"-@DrTedros #WorldHumanitarianDay|Username: World Health Organization (WHO)|Date: Wed Aug 18 13:39:50 +0000 2021|Hashtags: #COVID19 #WorldHumanitarianDay|Likes: 54|Retweets: 23|Url: twitter.com/14499829/status/1427988612717633539\n",
      "\n",
      "\n",
      "Tweet: It's #WorldHumanitarianDay\n",
      " \n",
      "The climate emergency is a humanitarian crisis.\n",
      "We must maximise the health benefits of tackling the #ClimateCrisis while avoiding its worst health impacts, and promote climate-resilient health systems everywhere.\n",
      "\n",
      "üëâ https://t.co/cM6yAJX0fE https://t.co/heviFQaWSJ|Username: World Health Organization (WHO)|Date: Thu Aug 19 10:10:30 +0000 2021|Hashtags: #WorldHumanitarianDay #ClimateCrisis|Likes: 262|Retweets: 64|Url: twitter.com/14499829/status/1428298318254415874\n",
      "\n",
      "\n",
      "Tweet: \"Climate crisis, the severe impact of the pandemic on lives and livelihoods, vaccine inequity and the large burden of noncommunicable diseases were discussed and concrete outcomes developed on how together we can tackle them.\"-@DrTedros|Username: World Health Organization (WHO)|Date: Fri Jul 02 12:38:13 +0000 2021|Hashtags: |Likes: 63|Retweets: 10|Url: twitter.com/14499829/status/1410940877191659522\n",
      "\n",
      "\n",
      "Tweet: \"On an almost day-to-day basis we are now seeing the impact of the climate crisis. \n",
      "Record breaking scorching heatwaves, catastrophic storms and changing weather patterns are impacting food systems, disease dispersion and societies at large. \"-@DrTedros|Username: World Health Organization (WHO)|Date: Fri Jul 02 12:48:34 +0000 2021|Hashtags: |Likes: 36|Retweets: 17|Url: twitter.com/14499829/status/1410943481988722688\n",
      "\n",
      "\n",
      "Tweet: \"I urge all countries to put these [Air Quality] guidelines to use, to save lives, support healthy communities, and help address the climate crisis. These guidelines come at an important time, ahead of the COP26 #ClimateChange Conference in November\"-@DrTedros #AirPollution|Username: World Health Organization (WHO)|Date: Wed Sep 22 13:30:11 +0000 2021|Hashtags: #ClimateChange #AirPollution|Likes: 252|Retweets: 59|Url: twitter.com/14499829/status/1440669759188529154\n",
      "\n",
      "\n",
      "Tweet: @DrTedros @ACTAccelerator @g20org \"Whether it‚Äôs pandemic response, new disease outbreaks of Marburg or Ebola, civil unrest, an earthquake in Haiti, or responding to the effects of the climate crisis; WHO will always be there working to save lives, strengthen science, find solutions and build solidarity\"-@DrTedros|Username: World Health Organization (WHO)|Date: Wed Aug 18 13:56:24 +0000 2021|Hashtags: |Likes: 123|Retweets: 34|Url: twitter.com/14499829/status/1427992783080591363\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wirte the queries respecting the format of the cleaner\n",
    "#specify the lang of the query to stem it and remove stopwords in a correct form\n",
    "query = {\"full_text\":\"climate crisis\", \"lang\":\"en\"}\n",
    "tweets_answers = query_search(query, inverted_index, stopwords_bylang, tweets, tf, idf, False)    \n",
    "top = 10\n",
    "print(\"Query: \", query[\"full_text\"])\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the seached query:\\n\".format(top, len(tweets_answers)))\n",
    "for t_id in tweets_answers[:top] :\n",
    "    print(t_id)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  depression\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 8 for the seached query:\n",
      "\n",
      "Tweet: RT @Alissonbecker: I am supporting @WHO and @FIFAcom on #WorldMentalHealthDay - let's support each other when we feel depressed. #ReachOut‚Ä¶|Username: World Health Organization (WHO)|Date: Mon Oct 11 04:38:21 +0000 2021|Hashtags: #WorldMentalHealthDay #ReachOut|Likes: 0|Retweets: 88|Url: twitter.com/14499829/status/1447421286871977987\n",
      "\n",
      "\n",
      "Tweet: RT @WHOMaldives: Some of the life changes that come with #ageing can cause depression \n",
      "\n",
      "If you think you might be at risk, this information‚Ä¶|Username: World Health Organization (WHO)|Date: Mon Oct 11 04:41:00 +0000 2021|Hashtags: #ageing|Likes: 0|Retweets: 21|Url: twitter.com/14499829/status/1447421956819664907\n",
      "\n",
      "\n",
      "Tweet: Think you may have #depression?\n",
      "\n",
      "#LetsTalk¬†about it. üíö\n",
      "\n",
      "Follow this thread for symptoms of depression, what you can do and where to seek help. üíö\n",
      "\n",
      "#WorldMentalHealthDay https://t.co/maqhBmYtEJ|Username: World Health Organization (WHO)|Date: Sun Oct 10 00:06:56 +0000 2021|Hashtags: #depression #LetsTalk #WorldMentalHealthDay|Likes: 231|Retweets: 117|Url: twitter.com/14499829/status/1446990596791541761\n",
      "\n",
      "\n",
      "Tweet: It's #WorldMentalHealthDay\n",
      "\n",
      "DYK: #Depression¬†is a leading cause of disability worldwide and is a major contributor to the overall global burden of disease.\n",
      "\n",
      "Depression can happen to anyone. #LetsTalk https://t.co/xz9agAXJI2|Username: World Health Organization (WHO)|Date: Sun Oct 10 06:15:47 +0000 2021|Hashtags: #WorldMentalHealthDay #Depression #LetsTalk|Likes: 202|Retweets: 120|Url: twitter.com/14499829/status/1447083421843562499\n",
      "\n",
      "\n",
      "Tweet: Some of the most common #mentalhealth conditions, depression and anxiety, can be treated with talking therapies, medication, or a combination of these.\n",
      " \n",
      "Laxmi, üáÆüá≥, shares how counsellor's support helped her overcome feelings of #depression.\n",
      " \n",
      "#WorldMentalHealthDay https://t.co/s4Ca8VJaT0|Username: World Health Organization (WHO)|Date: Sun Oct 10 19:52:35 +0000 2021|Hashtags: #mentalhealth #depression #WorldMentalHealthDay|Likes: 111|Retweets: 35|Url: twitter.com/14499829/status/1447288974813315079\n",
      "\n",
      "\n",
      "Tweet: Among active football players:\n",
      "23% report sleep disturbance\n",
      "9% have reported #depression¬†\n",
      "7% suffer from anxiety\n",
      "\n",
      "Among retired players:\n",
      "28% is struggling to sleep\n",
      "13% suffers from depression\n",
      "11% is having anxiety\n",
      "\n",
      "‚öΩÔ∏è¬†https://t.co/VMZxBomqlZ¬†#ReachOut https://t.co/4SnZeUSXVu|Username: World Health Organization (WHO)|Date: Tue Aug 03 08:01:39 +0000 2021|Hashtags: #depression #ReachOut|Likes: 151|Retweets: 40|Url: twitter.com/14499829/status/1422467687838593078\n",
      "\n",
      "\n",
      "Tweet: @DrTedros @G20 @ACTAccelerator \"Children who are exposed to violence and trauma are significantly more likely to develop #mentalhealth conditions, including depression, anxiety, post-traumatic-stress, and behavioral and substance use disorders. They are also more likely to die by suicide\"-@DrTedros|Username: World Health Organization (WHO)|Date: Wed Jul 07 13:40:06 +0000 2021|Hashtags: #mentalhealth|Likes: 75|Retweets: 38|Url: twitter.com/14499829/status/1412768388645068808\n",
      "\n",
      "\n",
      "Tweet: .@GordonBrown is widely credited with preventing a second Great Depression through his stewardship of the 2009 London #G20 summit.\n",
      "He mobilized world leaders to commit an additional USD1.1 trillion to restore credit, growth &amp; jobs amid the global financial crisis. https://t.co/LoL5sQ9YB0|Username: World Health Organization (WHO)|Date: Sun Sep 19 23:42:10 +0000 2021|Hashtags: #G20|Likes: 193|Retweets: 43|Url: twitter.com/14499829/status/1439736603820371973\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wirte the queries respecting the format of the cleaner\n",
    "#specify the lang of the query to stem it and remove stopwords in a correct form\n",
    "query = {\"full_text\":\"depression\", \"lang\":\"en\"}\n",
    "tweets_answers = query_search(query, inverted_index, stopwords_bylang, tweets, tf, idf, False)    \n",
    "top = 10\n",
    "print(\"Query: \", query[\"full_text\"])\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the seached query:\\n\".format(top, len(tweets_answers)))\n",
    "for t_id in tweets_answers[:top] :\n",
    "    print(t_id)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  vaccination coverage\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 15 for the seached query:\n",
      "\n",
      "Tweet: \"In those countries with low #COVID19 vaccination coverage, terrible scenes of hospitals overflowing are again becoming the norm. \n",
      "But no country is out of the woods yet.\"-@DrTedros|Username: World Health Organization (WHO)|Date: Fri Jul 02 12:52:43 +0000 2021|Hashtags: #COVID19|Likes: 38|Retweets: 23|Url: twitter.com/14499829/status/1410944523119869958\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"Meanwhile, countries with low vaccine coverage continue to see high case fatality rates\"-@DrTedros #VaccinEquity \n",
      "\n",
      "https://t.co/uUlxDj6NDY|Username: World Health Organization (WHO)|Date: Wed Sep 08 14:35:48 +0000 2021|Hashtags: #VaccinEquity|Likes: 45|Retweets: 19|Url: twitter.com/14499829/status/1435612842481405953\n",
      "\n",
      "\n",
      "Tweet: RT @DrTedros: Countries with high coverage are seeing a decoupling of #COVID19 cases &amp; deaths, whereas countries that can't access vaccines‚Ä¶|Username: World Health Organization (WHO)|Date: Sat Aug 14 11:41:44 +0000 2021|Hashtags: #COVID19|Likes: 0|Retweets: 182|Url: twitter.com/14499829/status/1426509340744327170\n",
      "\n",
      "\n",
      "Tweet: \"We call on countries with high #COVID19 vaccine coverage to swap delivery schedules with #COVAX and AVAT, and to fulfil their dose-sharing pledges immediately\"-@DrTedros #VaccinEquity|Username: World Health Organization (WHO)|Date: Thu Oct 07 13:59:18 +0000 2021|Hashtags: #COVID19 #COVAX #VaccinEquity|Likes: 100|Retweets: 19|Url: twitter.com/14499829/status/1446112903761850373\n",
      "\n",
      "\n",
      "Tweet: RT @DrTedros: #COVID19 is still raging, but people are dying at two different rates. In rich countries with high vaccination coverage, case‚Ä¶|Username: World Health Organization (WHO)|Date: Fri Sep 03 13:43:41 +0000 2021|Hashtags: #COVID19|Likes: 0|Retweets: 435|Url: twitter.com/14499829/status/1433787787006955536\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"Some countries with the highest vaccine coverage are now seeing a decoupling of #COVID19 cases and deaths, which is allowing them to reopen their societies without their health systems being overwhelmed\"-@DrTedros \n",
      "\n",
      "https://t.co/WcUsrmxW2M|Username: World Health Organization (WHO)|Date: Wed Sep 08 14:34:41 +0000 2021|Hashtags: #COVID19|Likes: 49|Retweets: 26|Url: twitter.com/14499829/status/1435612558824775680\n",
      "\n",
      "\n",
      "Tweet: WHO is supporting countries to get back on track with immunization by:\n",
      "\n",
      "‚úÖ¬†Restoring services &amp; vaccination campaigns\n",
      "‚úÖ¬†Amplifying vaccination info\n",
      "‚úÖ¬†closing gaps in immunization coverage\n",
      "\n",
      "and much more üëâhttps://t.co/bt6n7OAQrq https://t.co/8pbfhbs3nh|Username: World Health Organization (WHO)|Date: Thu Jul 15 06:34:09 +0000 2021|Hashtags: |Likes: 138|Retweets: 27|Url: twitter.com/14499829/status/1415560296719130625\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"Here is what we‚Äôve learned:\n",
      "\n",
      "‚úÖ This [#malaria] vaccine can be delivered through child health clinics by Ministries of Health, and readily reach children at high coverage levels\n",
      "\n",
      "‚úÖ Community demand for the vaccine is strong\"-@DrTedros #EndMalaria|Username: World Health Organization (WHO)|Date: Wed Oct 06 15:53:40 +0000 2021|Hashtags: #malaria #EndMalaria|Likes: 193|Retweets: 52|Url: twitter.com/14499829/status/1445779299726815236\n",
      "\n",
      "\n",
      "Tweet: WHO &amp; @NorwayMFA joined forces to to improve #COVID19 vaccine coverage &amp; uptake in #Uganda üá∫üá¨, aiming to achieve 60% of vaccination of people at highest risk.\n",
      "\n",
      "Read more üëâhttps://t.co/7hT3oHxDiG #WHOImpact https://t.co/yUvCSC9JHS|Username: World Health Organization (WHO)|Date: Sat Aug 28 06:18:51 +0000 2021|Hashtags: #COVID19 #Uganda #WHOImpact|Likes: 217|Retweets: 54|Url: twitter.com/14499829/status/1431501513080201217\n",
      "\n",
      "\n",
      "Tweet: @DrTedros \"In places with high vaccination coverage, Delta is spreading quickly; especially infecting unprotected and vulnerable people and steadily putting pressure back on health systems\"-@DrTedros #COVID19 \n",
      "\n",
      "https://t.co/AAY6DONlAx|Username: World Health Organization (WHO)|Date: Mon Jul 12 14:37:57 +0000 2021|Hashtags: #COVID19|Likes: 56|Retweets: 46|Url: twitter.com/14499829/status/1414594886976905224\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wirte the queries respecting the format of the cleaner\n",
    "#specify the lang of the query to stem it and remove stopwords in a correct form\n",
    "query = {\"full_text\":\"vaccination coverage\", \"lang\":\"en\"}\n",
    "tweets_answers = query_search(query, inverted_index, stopwords_bylang, tweets, tf, idf, False)    \n",
    "top = 10\n",
    "print(\"Query: \", query[\"full_text\"])\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the seached query:\\n\".format(top, len(tweets_answers)))\n",
    "for t_id in tweets_answers[:top] :\n",
    "    print(t_id)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1421870697094205445</td>\n",
       "      <td>5.733902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1416433609091653633</td>\n",
       "      <td>5.439723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1435906715497766918</td>\n",
       "      <td>4.598476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1443517908072730624</td>\n",
       "      <td>4.441924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1435598519595843585</td>\n",
       "      <td>4.441924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q_id             tweet_id     score\n",
       "0    0  1421870697094205445  5.733902\n",
       "1    0  1416433609091653633  5.439723\n",
       "2    0  1435906715497766918  4.598476\n",
       "3    0  1443517908072730624  4.441924\n",
       "4    0  1435598519595843585  4.441924"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the dataframe with our 5 queries to be evaluated\n",
    "queries = [{\"full_text\":\"covid19 pandemic\", \"lang\":\"en\"}, \n",
    "           {\"full_text\":\"vaccine africa\", \"lang\":\"en\"}, \n",
    "           {\"full_text\":\"climate crisis\", \"lang\":\"en\"}, \n",
    "           {\"full_text\":\"depression\", \"lang\":\"en\"}, \n",
    "           {\"full_text\":\"vaccination coverage\", \"lang\":\"en\"}]\n",
    "\n",
    "evdf = pd.DataFrame(columns = [\"q_id\", \"tweet_id\", \"score\"])\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    rank_scores, ranked_tweets = query_search(queries[i], inverted_index, stopwords_bylang, tweets, tf, idf, True)\n",
    "    for j in range(len(ranked_tweets)):\n",
    "        evdf = evdf.append({\"q_id\": i, \"tweet_id\": str(ranked_tweets[j]), \"score\": rank_scores[j]}, ignore_index=True)        \n",
    "evdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't run it again (only to evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\narray_judges=[]\\ni=0\\n#print queries with tweets to judge\\nfor index, row in evdf.iterrows():\\n    print(queries[row[\"q_id\"]][\"full_text\"])\\n    print(tweet_Printer(tweets, int(row[\"tweet_id\"])))\\n    array_judges.append(input())\\n    i += 1\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#judge the groud truth of each pair (query, tweet) in a binary way\n",
    "\"\"\"\n",
    "array_judges=[]\n",
    "i=0\n",
    "#print queries with tweets to judge\n",
    "for index, row in evdf.iterrows():\n",
    "    print(queries[row[\"q_id\"]][\"full_text\"])\n",
    "    print(tweet_Printer(tweets, int(row[\"tweet_id\"])))\n",
    "    array_judges.append(input())\n",
    "    i += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(array_judges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1421870697094205445</td>\n",
       "      <td>5.733902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1416433609091653633</td>\n",
       "      <td>5.439723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1435906715497766918</td>\n",
       "      <td>4.598476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1443517908072730624</td>\n",
       "      <td>4.441924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1435598519595843585</td>\n",
       "      <td>4.441924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1443289841698025473</td>\n",
       "      <td>4.300856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1441736058421477381</td>\n",
       "      <td>3.667770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1429724718693634052</td>\n",
       "      <td>3.667770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1438088306965762048</td>\n",
       "      <td>3.943840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1437865487879319561</td>\n",
       "      <td>3.554290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q_id             tweet_id     score  ground_truth\n",
       "0    0  1421870697094205445  5.733902             0\n",
       "1    0  1416433609091653633  5.439723             1\n",
       "2    0  1435906715497766918  4.598476             1\n",
       "3    0  1443517908072730624  4.441924             1\n",
       "4    0  1435598519595843585  4.441924             1\n",
       "5    0  1443289841698025473  4.300856             1\n",
       "6    0  1441736058421477381  3.667770             0\n",
       "7    0  1429724718693634052  3.667770             1\n",
       "8    1  1438088306965762048  3.943840             1\n",
       "9    1  1437865487879319561  3.554290             1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
    "\n",
    "evdf[\"ground_truth\"] = ground_truth\n",
    "evdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation techniques once we have the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_score, k=10):\n",
    "    '''    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth.\n",
    "    y_score: Predicted scores.\n",
    "    k : number of tweets to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    '''    \n",
    "    order = y_score.argsort()[::-1]\n",
    "    y_true = y_true.take(order)\n",
    "    relevant = np.sum(y_true[:k])\n",
    "    return float(relevant/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> For Query 0 Precision@3: 0.6666666666666666\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>score</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1421870697094205445</td>\n",
       "      <td>5.733902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1416433609091653633</td>\n",
       "      <td>5.439723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1435906715497766918</td>\n",
       "      <td>4.598476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1443517908072730624</td>\n",
       "      <td>4.441924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1435598519595843585</td>\n",
       "      <td>4.441924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q_id             tweet_id     score  ground_truth\n",
       "0    0  1421870697094205445  5.733902             0\n",
       "1    0  1416433609091653633  5.439723             1\n",
       "2    0  1435906715497766918  4.598476             1\n",
       "3    0  1443517908072730624  4.441924             1\n",
       "4    0  1435598519595843585  4.441924             1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query 0\n",
    "\n",
    "current_query = 0\n",
    "current_query_res = evdf[evdf[\"q_id\"] == current_query] \n",
    "k=3\n",
    "print(\"==> For Query {} Precision@{}: {}\\n\".format(current_query, k,\n",
    "                                precision_at_k(current_query_res[\"ground_truth\"], current_query_res[\"score\"], k)))\n",
    "\n",
    "current_query_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_at_k(y_true, y_score, k=10):    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth.\n",
    "    y_score: Predicted scores.\n",
    "    k : number of tweet to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    average precision @k : float\n",
    "    '''\n",
    "    gtp = np.sum(y_true[:k])\n",
    "    order = y_score.argsort()[::-1]\n",
    "    y_true = y_true.take(order)  \n",
    " \n",
    "    \n",
    "    ## if all tweets are not relevant\n",
    "    if gtp==0:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    prec_at_i = 0\n",
    "    \n",
    "    iters=k\n",
    "    if k > len(y_true):\n",
    "        iters=len(y_true)\n",
    "\n",
    "    for i in range(iters):\n",
    "        if y_true[i] == 1:\n",
    "            prec_at_i += precision_at_k(y_true, y_score, i+1)\n",
    "    \n",
    "    return prec_at_i/gtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107142857142857"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_precision_at_k(np.array(current_query_res[\"ground_truth\"]), np.array(current_query_res[\"score\"]), 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7250000000000002"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with average_precision_score of sklearn\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "k = 150\n",
    "average_precision_score(np.array(current_query_res[\"ground_truth\"]), np.array(current_query_res[\"score\"][:k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(search_res, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_res: search results dataset containing:\n",
    "        q_id: query id.\n",
    "        tweet_id: tweet id.\n",
    "        score: relevance predicted through td-idf.\n",
    "        y_true: actual relevance of the tweet for the query (ground truth).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean average precision @k : float\n",
    "    '''\n",
    "    \n",
    "    avp = []\n",
    "    for q in search_res[\"q_id\"].unique(): #loop over all query id\n",
    "        curr_data = search_res[search_res[\"q_id\"] == q]  # select data for current query\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"ground_truth\"]), np.array(curr_data[\"score\"]), k)) #append average precision for current query\n",
    "    return np.sum(avp)/len(avp) # return mean average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709123048668503"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_k = map_at_k(evdf, 20)\n",
    "map_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_at_k(search_res, k=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of tweets to consider.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Mean Reciprocal Rank\n",
    "    '''\n",
    "    RRs = []\n",
    "    \n",
    "    for q in search_res[\"q_id\"].unique():\n",
    "        \n",
    "        \n",
    "        y_true = np.array(search_res[search_res['q_id'] == q][\"ground_truth\"])\n",
    "        y_score = np.array(search_res[search_res['q_id'] == q][\"score\"])\n",
    "        \n",
    "        order = y_score.argsort()[::-1]     # get the list of indexes of the predicted score sorted in descending order.\n",
    "        y_true = y_true.take(order)   # sort the actual relevance label of the tweets based on predicted score and take first k.\n",
    "\n",
    "        if np.sum(y_true[:k])==0: # if there are not relevant doument return 0\n",
    "            RRs.append(0)\n",
    "        else:\n",
    "            RRs.append(1/(y_true.argmax()+1)) \n",
    "\n",
    "    return np.round(np.mean(RRs), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_k = mrr_at_k(evdf, 10)\n",
    "mrr_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(y_true, y_score,  k=10):\n",
    "    \n",
    "    order = y_score.argsort()[::-1] # get the list of indexes of the predicted score sorted in descending order.\n",
    "    y_true = y_true.take(order)[:k]  # sort the actual relevance label of the tweets based on predicted score\n",
    "\n",
    "    gain = [] # Compute gain \n",
    "    for i in range(len(y_true)):\n",
    "        gain.append((2**y_true[i])-1)\n",
    "    \n",
    "    discounts =[] # Compute denominator\n",
    "    for i in range(len(y_true)):\n",
    "        discounts.append(math.log2(i+2)) #we add +2 as the first position in array is 0 and first rank is 1\n",
    "    \n",
    "    division =[]\n",
    "    for i in range(len(gain)):\n",
    "        division.append(gain[i]/discounts[i])\n",
    "        \n",
    "    return np.sum(division) #return dcg@k\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k=10):\n",
    "    \n",
    "  \n",
    "    dcg_max = dcg_at_k(y_true, y_true, k) # Ideal dcg order by y_true as we want the sort by relevance\n",
    "    \n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    \n",
    "    return np.round((dcg_at_k(y_true, y_score, k))/dcg_max,4)  # return ndcg@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg@10 for query with q_id=0: 0.7983\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "labels = np.array(current_query_res[\"ground_truth\"])\n",
    "scores = np.array(current_query_res[\"score\"])\n",
    "ndcg_k = np.round(ndcg_at_k(labels, scores, k),4)\n",
    "print(\"ndcg@{} for query with q_id={}: {}\".format(k,current_query,ndcg_k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> For Query 0 Precision@10: 0.6\n",
      "Average Precission@10 for query with q_id=0: 0.7107142857142857\n",
      "ndcg@10 for query with q_id=0: 0.7983\n",
      "\n",
      "==> For Query 1 Precision@10: 0.7\n",
      "Average Precission@10 for query with q_id=1: 0.7799144037780401\n",
      "ndcg@10 for query with q_id=1: 0.7506\n",
      "\n",
      "==> For Query 2 Precision@10: 0.3\n",
      "Average Precission@10 for query with q_id=2: 0.4777777777777777\n",
      "ndcg@10 for query with q_id=2: 0.6183\n",
      "\n",
      "==> For Query 3 Precision@10: 0.5\n",
      "Average Precission@10 for query with q_id=3: 0.6295238095238095\n",
      "ndcg@10 for query with q_id=3: 0.7486\n",
      "\n",
      "==> For Query 4 Precision@10: 0.8\n",
      "Average Precission@10 for query with q_id=4: 0.7566312475403385\n",
      "ndcg@10 for query with q_id=4: 0.7137\n",
      "\n",
      "MAP@10: 0.6767494331065761\n",
      "MRR@10: 0.5667\n"
     ]
    }
   ],
   "source": [
    "#All evaluations techniques for all queries\n",
    "k = 10\n",
    "for i in range(5):\n",
    "    current_query = i\n",
    "    current_query_res = evdf[evdf[\"q_id\"] == current_query] \n",
    "    print(\"\\n==> For Query {} Precision@{}: {}\".format(current_query, k,\n",
    "                                precision_at_k(current_query_res[\"ground_truth\"], current_query_res[\"score\"], k)))\n",
    "\n",
    "    print(\"Average Precission@{} for query with q_id={}: {}\".format(k,current_query,avg_precision_at_k(np.array(current_query_res[\"ground_truth\"]), np.array(current_query_res[\"score\"]), 150)))\n",
    "\n",
    "    \n",
    "\n",
    "    labels = np.array(current_query_res[\"ground_truth\"])\n",
    "    scores = np.array(current_query_res[\"score\"])\n",
    "    ndcg_k = np.round(ndcg_at_k(labels, scores, k),4)\n",
    "    print(\"ndcg@{} for query with q_id={}: {}\".format(k,current_query,ndcg_k))\n",
    "    \n",
    "print(\"\\nMAP@{}: {}\".format(k,map_at_k(evdf, k)))\n",
    "\n",
    "print(\"MRR@{}: {}\".format(k,mrr_at_k(evdf, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_tweets = []\n",
    "for tweet_num, tweet in tweets.items(): \n",
    "        #get the terms cleaned \n",
    "        clean_tweets.append(clean_data(tweet, stopwords_bylang))\n",
    "\n",
    "model = Word2Vec(clean_tweets, workers=4, min_count=50, window=10, sample=1e-3)\n",
    "\n",
    "#print (model.wv.most_similar('memory'))\n",
    "\n",
    "X = model.wv[model.wv.key_to_index]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
